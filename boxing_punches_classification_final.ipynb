{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost"
      ],
      "metadata": {
        "id": "WC8Ikt_ot7y7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NsE-ZZoJlKgG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import plotly.graph_objs as go\n",
        "import plotly.express as px\n",
        "\n",
        "from scipy.stats import moment, skew, kurtosis\n",
        "\n",
        "\n",
        "from joblib import load"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reading and filtering data"
      ],
      "metadata": {
        "id": "uVRE1Vm6irkk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Files from the dataset have data about the sensor in the first 3 lines, we will skip these lines."
      ],
      "metadata": {
        "id": "HWUZmqgTJqLu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def skip_fun(x):\n",
        "    return x in (0, 1, 2)"
      ],
      "metadata": {
        "id": "DJ4fx_H4o3qV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the dataset and rename the columns for convenience"
      ],
      "metadata": {
        "id": "CkgnvworKd-c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = \"/data/fight_file/14.txt\"\n",
        "data = pd.read_csv(data_path, skiprows=skip_fun)\n",
        "\n",
        "data.rename(columns={\"Time (s)\": \"Time\",\n",
        "                      \" X (m/s2)\": \"X\",\n",
        "                      \" Y (m/s2)\": \"Y\",\n",
        "                      \" Z (m/s2)\": \"Z\",\n",
        "                      \" R (m/s2)\": \"R\",\n",
        "                      \" Theta (deg)\": \"Theta\",\n",
        "                      \" Phi (deg)\": \"Phi\",}, inplace=True)"
      ],
      "metadata": {
        "id": "r8XgTsY7lbZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at our data"
      ],
      "metadata": {
        "id": "8gE1vkW5Ktj6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trace1 = go.Scatter(x=data[\"Time\"], y=data[\"X\"], name=\"acc_X\")\n",
        "trace2 = go.Scatter(x=data[\"Time\"], y=data[\"Y\"], name=\"acc_Y\")\n",
        "trace3 = go.Scatter(x=data[\"Time\"], y=data[\"Z\"], name=\"acc_Z\")\n",
        "trace4 = go.Scatter(x=data[\"Time\"], y=data[\"R\"], name=\"acc_full\")\n",
        "trace5 = go.Scatter(x=data[\"Time\"], y=data[\"Theta\"], name=\"Theta\")\n",
        "trace6 = go.Scatter(x=data[\"Time\"], y=data[\"Phi\"], name=\"Phi\")\n",
        "\n",
        "\n",
        "data_plot = [trace1, trace2, trace3, trace4, trace5, trace6]\n",
        "layout = {\"title\": \"Dependence of acceleration on time\",\n",
        "          \"xaxis_title\" : \"Time (point number)\",\n",
        "          \"yaxis_title\" : \"Acceleration\",\n",
        "          \"template\" : \"plotly\"}\n",
        "\n",
        "fig = go.Figure(data=data_plot, layout=layout)\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "2ePVgq2z-Blt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data filtering using the Kalman filter\n",
        "# https://habr.com/ru/post/588270/\n",
        "def kalman(f, q=0.5, r=7):\n",
        "    if not hasattr(kalman, \"Accumulated_Error\"):\n",
        "        kalman.Accumulated_Error = 1\n",
        "        kalman.kalman_adc_old = 0\n",
        "\n",
        "    if abs(f-kalman.kalman_adc_old)/50 > 0.25:\n",
        "        Old_Input = f*0.382 + kalman.kalman_adc_old*0.618\n",
        "    else:\n",
        "        Old_Input = kalman.kalman_adc_old\n",
        "\n",
        "    Old_Error_All = (kalman.Accumulated_Error**2 + q**2)**(1/2)\n",
        "    H = Old_Error_All**2/(Old_Error_All**2 + r**2)\n",
        "    kalman_adc = Old_Input + H * (f - Old_Input)\n",
        "    kalman.Accumulated_Error = ((1 - H)*Old_Error_All**2)**(1/2)\n",
        "    kalman.kalman_adc_old = kalman_adc\n",
        "\n",
        "    return kalman_adc\n",
        "\n",
        "\n",
        "def normalise_kalman(func):\n",
        "    o = []\n",
        "    for p in func:\n",
        "        res = kalman(p)\n",
        "        o.append(res)\n",
        "    return o"
      ],
      "metadata": {
        "id": "p-7oHs9jrslZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For data filtering, we use a combination of the median filter (to remove sharp peaks) and the Kalman method (to smooth the data)"
      ],
      "metadata": {
        "id": "o7mRrV8EK91V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_filt = data.copy()\n",
        "\n",
        "# Using the median filter\n",
        "for i in [\"X\", \"Y\", \"Z\", \"R\", \"Theta\", \"Phi\"]:\n",
        "    data_filt[i] = data_filt[[i]].rolling(10).mean()\n",
        "    data_filt.loc[range(9), [i]] = data.loc[range(9), [i]]\n",
        "\n",
        "# Using the Kalman method\n",
        "for i in [\"X\", \"Y\", \"Z\", \"R\", \"Theta\", \"Phi\"]:\n",
        "    data_filt[i] = normalise_kalman(data_filt[i])\n",
        "\n",
        "# Let's break the signal down into separate actions that will be classified by our model\n",
        "data_filt[\"action_index\"] = data_filt.index // 120 "
      ],
      "metadata": {
        "id": "vCapGupyp0mu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Finding punches in a signal"
      ],
      "metadata": {
        "id": "LtIKpNPRi4W-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A function that counts the number of signal crossings of its average value\n",
        "def n_cross(x):\n",
        "    x_del = x - x.mean()\n",
        "    return (np.diff(np.sign(x_del)) != 0).sum()\n",
        "\n",
        "# A function that counts the number of points\n",
        "# where the signal is greater than the maximum value of the sensor\n",
        "def n_sensor_limit_max(x):\n",
        "    return (x >= 77).sum()\n",
        "\n",
        "# A function that counts the number of points\n",
        "# where the signal is greater than the minimum value of the sensor\n",
        "def n_sensor_limit_min(x):\n",
        "    return (x <= -77).sum()"
      ],
      "metadata": {
        "id": "CRvfwz0hrpsG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare a dataset for a model that looks for punches in the fight signal"
      ],
      "metadata": {
        "id": "Tb_f86EKPtZN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For each action, we will calculate the statistical features that will be used in the model\n",
        "# The set of statistical features is slightly different for data from the gyroscope and accelerometer\n",
        "# So we count them separately\n",
        "data_feature_acc = data_filt.loc[:, [\"X\", \"Y\", \"Z\", \"R\", \"action_index\"]]\\\n",
        "    .groupby(\"action_index\").aggregate([\n",
        "    lambda x: x.mean(),\n",
        "    lambda x: x.std(),\n",
        "    lambda x: x.max(),\n",
        "    lambda x: x.min(),\n",
        "    lambda x: x.max() - x.min(),\n",
        "    lambda x: np.percentile(x, 25),\n",
        "    lambda x: np.percentile(x, 50),\n",
        "    lambda x: np.percentile(x, 75),\n",
        "    lambda x: moment(x, moment=3),\n",
        "    lambda x: moment(x, moment=4),\n",
        "    lambda x: skew(x),\n",
        "    lambda x: kurtosis(x),\n",
        "    lambda x: n_cross(x),\n",
        "    lambda x: n_sensor_limit_max(x),\n",
        "    lambda x: n_sensor_limit_min(x)])\n",
        "\n",
        "# Remove transformation artifacts\n",
        "data_feature_acc = data_feature_acc.T.reset_index().T.drop([\"level_0\", \"level_1\"])\n",
        "data_feature_acc = data_feature_acc.apply(lambda x: x.astype(float))\n",
        "\n",
        "# Similarly for the gyroscope\n",
        "data_feature_cor = data_filt.loc[:, [\"Theta\", \"Phi\", \"action_index\"]]\\\n",
        "    .groupby(\"action_index\").aggregate([\n",
        "    lambda x: x.mean(),\n",
        "    lambda x: x.std(),\n",
        "    lambda x: x.max(),\n",
        "    lambda x: x.min(),\n",
        "    lambda x: x.max() - x.min(),\n",
        "    lambda x: np.percentile(x, 25),\n",
        "    lambda x: np.percentile(x, 50),\n",
        "    lambda x: np.percentile(x, 75),\n",
        "    lambda x: skew(x),\n",
        "    lambda x: kurtosis(x),\n",
        "    lambda x: n_cross(x),\n",
        "    lambda x: n_sensor_limit_max(x),\n",
        "    lambda x: n_sensor_limit_min(x)])\n",
        "\n",
        "data_feature_cor = data_feature_cor.T.reset_index().T.drop([\"level_0\", \"level_1\"])\n",
        "data_feature_cor = data_feature_cor.apply(lambda x: x.astype(float))\n",
        "\n",
        "# Merge dataset => We received a ready dataset for the first model\n",
        "data_feature_acc.reset_index(inplace=True)\n",
        "data_feature_cor.reset_index(inplace=True)\n",
        "X_test = pd.merge(data_feature_acc, data_feature_cor, on=\"action_index\")\n",
        "X_test.drop(\"action_index\", axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "udZ_V117q9JU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a prediction of the model (detect punchs)\n",
        "model = load(\"/model/punch_detect_catboost.joblib\")\n",
        "model_pred = model.predict(X_test)\n",
        "# Transfer the prediction to the initial dataset\n",
        "pred_df = pd.DataFrame({\"action_index\": range(model_pred.shape[0]),\n",
        "                        \"model_predict\": model_pred})\n",
        "data_filt = pd.merge(data_filt, pred_df, how=\"outer\", on=\"action_index\")"
      ],
      "metadata": {
        "id": "-H0LKdvOq2Qj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Got detected punchs in our signal. Draw them."
      ],
      "metadata": {
        "id": "_lGl8BG-QAUG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.scatter(x=data_filt.index,\n",
        "                 y=data_filt[\"R\"],\n",
        "                 color=data_filt[\"model_predict\"])\\\n",
        "    .update_layout(title=\"Залежність повного прискорення від часу (color: model_predict_is_punch)\",\n",
        "                   xaxis_title=\"Номер точки(час)\",\n",
        "                   yaxis_title=\"Прискорення\",\n",
        "                   template='plotly')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "bCdNQXTGuLDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Punch classification"
      ],
      "metadata": {
        "id": "WAa751I9jyYv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Divide the signal according to the results of the first model into separate punches"
      ],
      "metadata": {
        "id": "QcVrbPU0QbtJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_filt[\"action_index2\"] = 0\n",
        "action_ind = 0\n",
        "for i in range(1, data_filt.shape[0]):\n",
        "    if data_filt.loc[i, \"model_predict\"] != data_filt.loc[i - 1, \"model_predict\"]:\n",
        "        action_ind += 1\n",
        "    data_filt.loc[i, \"action_index2\"] = action_ind"
      ],
      "metadata": {
        "id": "OYIIaBKTuazx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract parts of the signal where there are punches"
      ],
      "metadata": {
        "id": "8ojcpnFkTexp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_punch_filt = data_filt[data_filt[\"model_predict\"] == 1]"
      ],
      "metadata": {
        "id": "Ju-rGmmd0NHV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare a dataset for a model that сlassifies punches"
      ],
      "metadata": {
        "id": "By1dpN_VTpP_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For each action, we will calculate the statistical features that will be used in the model\n",
        "# The set of statistical features is slightly different for data from the gyroscope and accelerometer\n",
        "# So we count them separately\n",
        "data_feature_acc = data_punch_filt.loc[:, [\"X\", \"Y\", \"Z\", \"R\", \"action_index2\"]]\\\n",
        "    .groupby(\"action_index2\").aggregate([\n",
        "    lambda x: x.mean(),\n",
        "    lambda x: x.std(),\n",
        "    lambda x: x.max(),\n",
        "    lambda x: x.min(),\n",
        "    lambda x: x.max() - x.min(),\n",
        "    lambda x: np.percentile(x, 25),\n",
        "    lambda x: np.percentile(x, 50),\n",
        "    lambda x: np.percentile(x, 75),\n",
        "    lambda x: moment(x, moment=3),\n",
        "    lambda x: moment(x, moment=4),\n",
        "    lambda x: skew(x),\n",
        "    lambda x: kurtosis(x),\n",
        "    lambda x: n_cross(x),\n",
        "    lambda x: n_sensor_limit_max(x),\n",
        "    lambda x: n_sensor_limit_min(x)])\n",
        "\n",
        "# Remove transformation artifacts\n",
        "data_feature_acc = data_feature_acc.T.reset_index().T.drop([\"level_0\", \"level_1\"])\n",
        "data_feature_acc = data_feature_acc.apply(lambda x: x.astype(float))\n",
        "\n",
        "# Similarly for the gyroscope\n",
        "data_feature_cor = data_punch_filt.loc[:, [\"Theta\", \"Phi\", \"action_index2\"]]\\\n",
        "    .groupby(\"action_index2\").aggregate([\n",
        "    lambda x: x.mean(),\n",
        "    lambda x: x.std(),\n",
        "    lambda x: x.max(),\n",
        "    lambda x: x.min(),\n",
        "    lambda x: x.max() - x.min(),\n",
        "    lambda x: np.percentile(x, 25),\n",
        "    lambda x: np.percentile(x, 50),\n",
        "    lambda x: np.percentile(x, 75),\n",
        "    lambda x: skew(x),\n",
        "    lambda x: kurtosis(x),\n",
        "    lambda x: n_cross(x),\n",
        "    lambda x: n_sensor_limit_max(x),\n",
        "    lambda x: n_sensor_limit_min(x)])\n",
        "\n",
        "data_feature_cor = data_feature_cor.T.reset_index().T.drop([\"level_0\", \"level_1\"])\n",
        "data_feature_cor = data_feature_cor.apply(lambda x: x.astype(float))\n",
        "\n",
        "# Merge dataset => We received a ready dataset for the second model\n",
        "data_feature_acc.reset_index(inplace=True)\n",
        "data_feature_cor.reset_index(inplace=True)\n",
        "X_test2 = pd.merge(data_feature_acc, data_feature_cor, on=\"action_index2\")\n",
        "X_test2.drop(\"action_index2\", axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "Dtu73Mcv2JtL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a prediction of the model (сlassifies punchs)\n",
        "model2 = load(\"/model/punch_classification_catboost.joblib\")\n",
        "model_pred2 = model2.predict(X_test2)\n",
        "# Transfer the prediction to the initial dataset\n",
        "pred_df = pd.DataFrame({\"action_index2\": data_punch_filt[\"action_index2\"].unique(),\n",
        "                        \"model_predict2\": model_pred2[:, 0]})\n",
        "data_filt = pd.merge(data_filt, pred_df, how=\"outer\", on=\"action_index2\")\n",
        "\n",
        "data_filt.fillna(0,inplace=True)"
      ],
      "metadata": {
        "id": "eP0M9RVkuLLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Got the final result. Draw them.\n",
        "\n",
        "In signal detected and classify punches."
      ],
      "metadata": {
        "id": "xP3gO74HhDmD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.scatter(x=data_filt.index,\n",
        "                 y=data_filt[\"R\"],\n",
        "                 color=data_filt[\"model_predict2\"])\\\n",
        "    .update_layout(title=\"Залежність повного прискорення від часу (color: model_predict_punch_type)\",\n",
        "                   xaxis_title=\"Номер точки(час)\",\n",
        "                   yaxis_title=\"Прискорення\",\n",
        "                   template='plotly')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "toqvRi2UuLO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comparison of results"
      ],
      "metadata": {
        "id": "gU9kXUYkkGlE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's compare the final result with the true values.\n",
        "True values are taken from the markup file for this file."
      ],
      "metadata": {
        "id": "nqcFtsTohjrP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_filt[\"real_punch_type\"] = 0\n",
        "\n",
        "jab_ind = [9, 10, 11, 22, 23, 24, 34, 35, 36, 77, 78, 79, 119, 120, 121]\n",
        "\n",
        "uppercut_ind = [56, 57, 58, 82, 83, 84, 112, 113, 114, 123, 124, 138, 139, 140]\n",
        "                \n",
        "hook_ind = [47, 48, 49, 59, 60, 61, 93, 94, 95, 126, 127, 135, 136]\n",
        "\n",
        "data_filt.loc[data_filt[\"action_index\"].isin(jab_ind), \"real_punch_type\"] = 1\n",
        "data_filt.loc[data_filt[\"action_index\"].isin(uppercut_ind ), \"real_punch_type\"] = 2\n",
        "data_filt.loc[data_filt[\"action_index\"].isin(hook_ind), \"real_punch_type\"] = 3"
      ],
      "metadata": {
        "id": "AxuBSaMSuLSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Draw true labels"
      ],
      "metadata": {
        "id": "IaVji7Vkh9MV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.scatter(x=data_filt.index,\n",
        "                 y=data_filt[\"R\"],\n",
        "                 color=data_filt[\"real_punch_type\"])\\\n",
        "    .update_layout(title=\"Залежність повного прискорення від часу (color: real_punch_type)\",\n",
        "                   xaxis_title=\"Номер точки(час)\",\n",
        "                   yaxis_title=\"Прискорення\",\n",
        "                   template='plotly')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "lNUBj9CGuLVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S8tMsB6NuLYq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}